from fastapi import APIRouter, Depends, HTTPException, Body
from fastapi.responses import StreamingResponse
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from typing import List, Optional
import json
import asyncio
from pydantic import BaseModel

from database import get_db
from models import User, UserSettings, Conversation, NodeType, Node
from auth import get_current_user
from encryption import decrypt_key
from openrouter_service import OpenRouterClient, AVAILABLE_MODELS
from council_engine import CouncilEngine
from engines.dxo_engine import DxOEngine
from sqlalchemy import desc

router = APIRouter()

@router.get("/models")
async def get_models(current_user: User = Depends(get_current_user)):
    return AVAILABLE_MODELS

class CouncilRequest(BaseModel):
    prompt: str
    council_members: List[str]
    chairman_model: str

@router.post("/council/start")
async def start_council_session(
    request: CouncilRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    # Retrieve API Key
    if not current_user.settings or not current_user.settings.encrypted_api_key:
        raise HTTPException(status_code=400, detail="OpenRouter API Key not configured in Settings")
    
    api_key = decrypt_key(current_user.settings.encrypted_api_key, current_user.id)
    
    # Create Conversation
    conversation = Conversation(
        user_id=current_user.id,
        title=request.prompt[:50]
    )
    db.add(conversation)
    await db.commit()
    await db.refresh(conversation)
    
    # Create Root Node
    root_node = Node(
        conversation_id=conversation.id,
        type=NodeType.ROOT.value,
        content=request.prompt,
        model_name="user"
    )
    db.add(root_node)
    await db.commit()
    
    return {"conversation_id": conversation.id}

class CouncilRunRequest(BaseModel):
    prompt: str
    council_members: List[str] = []
    chairman_model: str = "openai/gpt-4o"
    method: str = "dag" # dag, ensemble, or dxo
    roles: List[dict] = [] # List of {name, model, instructions}
    max_iterations: int = 5 # Default max loops for DxO

@router.post("/council/run")
async def run_council(
    request: CouncilRunRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    # Verify API Key
    result = await db.execute(select(UserSettings).where(UserSettings.user_id == current_user.id))
    settings = result.scalars().first()
    if not settings or not settings.encrypted_api_key:
        raise HTTPException(status_code=400, detail="No API Key")
    
    api_key = decrypt_key(settings.encrypted_api_key, current_user.id)
    
    # Create Conversation & Root Node immediately
    conversation = Conversation(
        user_id=current_user.id,
        title=request.prompt[:50],
        method=request.method
    )
    db.add(conversation)
    await db.commit()
    await db.refresh(conversation)
    
    root_node = Node(conversation_id=conversation.id, type=NodeType.ROOT.value, content=request.prompt, model_name="user")
    db.add(root_node)
    await db.commit()
    await db.refresh(root_node) # Refresh to get ID

    async def event_stream():
        # Setup context
        # We need a new session for the async generator because the dependency one might close?
        # Actually, FastAPI handles dependency lifetime. But running long process...
        # Let's use the passed `db` but we must ensure we commit often.
        
        try:
            client = OpenRouterClient(api_key)
            engine = CouncilEngine(db, current_user, client)
            
            yield f"data: {json.dumps({'type': 'start', 'conversation_id': conversation.id})}\n\n"
            
            if request.method == "ensemble":
                 # 1. Parallel Research (from all models in parallel)
                yield f"data: {json.dumps({'type': 'status', 'message': 'All models are researching in parallel...'})}\n\n"
                # For ensemble, we treat root as the plan/prompt directly
                research_nodes = await engine.run_ensemble_research(conversation.id, root_node, request.council_members)
                for node in research_nodes:
                     yield f"data: {json.dumps({'type': 'node', 'node': {'id': node.id, 'type': 'research', 'content': node.content, 'model': node.model_name}})}\n\n"

                # 2. Synthesis (Anonymized)
                yield f"data: {json.dumps({'type': 'status', 'message': 'Synthesizing anonymized responses...'})}\n\n"
                synthesis_node = await engine.run_ensemble_synthesis(conversation.id, root_node, research_nodes, request.chairman_model)
                yield f"data: {json.dumps({'type': 'node', 'node': {'id': synthesis_node.id, 'type': 'synthesis', 'content': synthesis_node.content, 'model': synthesis_node.model_name}})}\n\n"

            elif request.method == "dxo":
                dxo_engine = DxOEngine(db, current_user, client)
                yield f"data: {json.dumps({'type': 'status', 'message': 'Initializing DxO Virtual Panel...'})}\n\n"
                async for event in dxo_engine.run_dxo_pipeline(conversation.id, root_node, request.roles, max_iterations=request.max_iterations):
                    yield f"data: {event}\n\n"

            else:
                # Default DAG flow
                # 1. Coordinator
                yield f"data: {json.dumps({'type': 'status', 'message': 'Coordinator is creating a plan...'})}\n\n"
                plan_node = await engine.run_coordinator(conversation.id, root_node, request.chairman_model)
                yield f"data: {json.dumps({'type': 'node', 'node': {'id': plan_node.id, 'type': 'plan', 'content': plan_node.content}})}\n\n"

                # 2. Researchers
                yield f"data: {json.dumps({'type': 'status', 'message': 'Council members are researching...'})}\n\n"
                research_nodes = await engine.run_researchers(conversation.id, plan_node, request.council_members)
                for node in research_nodes:
                    yield f"data: {json.dumps({'type': 'node', 'node': {'id': node.id, 'type': 'research', 'content': node.content, 'model': node.model_name}})}\n\n"

                # 3. Critics
                yield f"data: {json.dumps({'type': 'status', 'message': 'Critics are reviewing findings...'})}\n\n"
                critique_nodes = await engine.run_critics(conversation.id, research_nodes, request.council_members)
                for node in critique_nodes:
                    yield f"data: {json.dumps({'type': 'node', 'node': {'id': node.id, 'type': 'critique', 'content': node.content, 'model': node.model_name}})}\n\n"

                # 4. Synthesis
                yield f"data: {json.dumps({'type': 'status', 'message': 'Chairman is synthesizing the final answer...'})}\n\n"
                synthesis_node = await engine.run_synthesis(conversation.id, plan_node, research_nodes, critique_nodes, request.chairman_model)
                yield f"data: {json.dumps({'type': 'node', 'node': {'id': synthesis_node.id, 'type': 'synthesis', 'content': synthesis_node.content, 'model': synthesis_node.model_name}})}\n\n"
            
            yield f"data: {json.dumps({'type': 'done'})}\n\n"
        except Exception as e:
            # Send error to frontend before closing stream
            import traceback
            import logging
            error_msg = str(e)
            error_trace = traceback.format_exc()
            logging.error(f"Error in council stream: {error_trace}")
            yield f"data: {json.dumps({'type': 'error', 'message': error_msg})}\n\n"
            # Don't re-raise - let the stream close gracefully

    return StreamingResponse(event_stream(), media_type="text/event-stream")

@router.get("/history")
async def get_history(
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    result = await db.execute(
        select(Conversation)
        .where(Conversation.user_id == current_user.id)
        .order_by(desc(Conversation.created_at))
    )
    conversations = result.scalars().all()
    return conversations

@router.get("/history/{conversation_id}")
async def get_conversation(
    conversation_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    # Verify ownership
    result = await db.execute(
        select(Conversation).where(
            Conversation.id == conversation_id,
            Conversation.user_id == current_user.id
        )
    )
    conversation = result.scalars().first()
    if not conversation:
        raise HTTPException(status_code=404, detail="Conversation not found")
        
    # Fetch nodes
    result = await db.execute(
        select(Node).where(Node.conversation_id == conversation_id)
    )
    nodes = result.scalars().all()
    return {"conversation": conversation, "nodes": nodes}

class SuperChatRequest(BaseModel):
    prompt: str
    conversation_id: Optional[int] = None
    council_members: List[str]
    chairman_model: str

@router.post("/superchat/chat")
async def superchat_chat(
    request: SuperChatRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    # Verify API Key
    result = await db.execute(select(UserSettings).where(UserSettings.user_id == current_user.id))
    settings = result.scalars().first()
    if not settings or not settings.encrypted_api_key:
        raise HTTPException(status_code=400, detail="No API Key")

    api_key = decrypt_key(settings.encrypted_api_key, current_user.id)

    conversation_id = request.conversation_id
    parent_node_id = None
    last_synthesis_content = ""

    if conversation_id:
        # Verify ownership
        result = await db.execute(
            select(Conversation).where(
                Conversation.id == conversation_id,
                Conversation.user_id == current_user.id
            )
        )
        conversation = result.scalars().first()
        if not conversation:
            raise HTTPException(status_code=404, detail="Conversation not found")

        # Find last synthesis node
        result = await db.execute(
            select(Node)
            .where(Node.conversation_id == conversation_id, Node.type == NodeType.SYNTHESIS.value)
            .order_by(desc(Node.id))
            .limit(1)
        )
        last_synthesis_node = result.scalars().first()
        if last_synthesis_node:
            parent_node_id = last_synthesis_node.id
            last_synthesis_content = last_synthesis_node.content
    else:
        # Create new conversation
        conversation = Conversation(
            user_id=current_user.id,
            title=request.prompt[:50],
            method="superchat"
        )
        db.add(conversation)
        await db.commit()
        await db.refresh(conversation)
        conversation_id = conversation.id

    # Create User Node (Root for this turn)
    user_node = Node(
        conversation_id=conversation_id,
        parent_id=parent_node_id,
        type=NodeType.ROOT.value, # Using ROOT as the type for user input in each turn
        content=request.prompt,
        model_name="user"
    )
    db.add(user_node)
    await db.commit()
    await db.refresh(user_node)

    async def event_stream():
        try:
            client = OpenRouterClient(api_key)
            engine = CouncilEngine(db, current_user, client)

            yield f"data: {json.dumps({'type': 'start', 'conversation_id': conversation_id})}\n\n"

            # Send User Node to client immediately
            yield f"data: {json.dumps({'type': 'node', 'node': {'id': user_node.id, 'parent_id': user_node.parent_id, 'type': 'root', 'content': user_node.content, 'model': user_node.model_name}})}\n\n"

            # Construct Ensemble Prompt
            ensemble_prompt = request.prompt
            if last_synthesis_content:
                ensemble_prompt = f"Context from previous turn:\n{last_synthesis_content}\n\nNew Request: {request.prompt}"

            # We treat the user_node as the root for this turn.
            # However, `run_ensemble_research` uses `root_node.content`.
            # We want to use `ensemble_prompt` but `run_ensemble_research` reads from node.
            # We can create a temporary object or modify `run_ensemble_research` to accept prompt override.
            # Or simpler: Just create a dummy node object in memory with the combined content?
            # Or better: Pass the combined prompt to `run_ensemble_research`.
            # Checking `council_engine.py`: `prompt = f'... user has asked: "{root_node.content}" ...'`
            # So I should probably just modify `run_ensemble_research` to take an optional `prompt_override`.
            # OR I can just create a fake node object with the combined content.

            class MockNode:
                def __init__(self, id, content):
                    self.id = id
                    self.content = content

            mock_root = MockNode(user_node.id, ensemble_prompt)

            # 1. Research
            yield f"data: {json.dumps({'type': 'status', 'message': 'Council members are researching...'})}\n\n"
            research_nodes = await engine.run_ensemble_research(conversation_id, mock_root, request.council_members)
            for node in research_nodes:
                 yield f"data: {json.dumps({'type': 'node', 'node': {'id': node.id, 'parent_id': node.parent_id, 'type': 'research', 'content': node.content, 'model': node.model_name}})}\n\n"

            # 2. Synthesis
            yield f"data: {json.dumps({'type': 'status', 'message': 'Chairman is synthesizing...'})}\n\n"
            # Note: run_ensemble_synthesis uses root_node.content for context.
            synthesis_node = await engine.run_ensemble_synthesis(conversation_id, mock_root, research_nodes, request.chairman_model)
            yield f"data: {json.dumps({'type': 'node', 'node': {'id': synthesis_node.id, 'parent_id': synthesis_node.parent_id, 'type': 'synthesis', 'content': synthesis_node.content, 'model': synthesis_node.model_name}})}\n\n"

            yield f"data: {json.dumps({'type': 'done'})}\n\n"

        except Exception as e:
            import traceback
            import logging
            error_msg = str(e)
            error_trace = traceback.format_exc()
            logging.error(f"Error in superchat stream: {error_trace}")
            yield f"data: {json.dumps({'type': 'error', 'message': error_msg})}\n\n"

    return StreamingResponse(event_stream(), media_type="text/event-stream")
